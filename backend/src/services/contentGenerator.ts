import { User } from '../models/database';

export interface GeneratedContent {
  text: string;
  imagePrompt: string;
}

export class ContentGenerator {
  private llmApiKey: string;
  private llmApiUrl: string;
  private imageApiKey: string;
  private imageApiUrl: string;

  constructor() {
    // Read from env at runtime, not at instantiation
    this.llmApiKey = process.env.LLM_API_KEY || '';
    this.llmApiUrl = process.env.LLM_API_URL || 'https://api.openai.com/v1/chat/completions';
    this.imageApiKey = process.env.IMAGE_API_KEY || '';
    this.imageApiUrl = process.env.IMAGE_API_URL || '';
  }

  // Helper method to refresh env vars (call this if env changes)
  private reloadEnv() {
    this.llmApiKey = process.env.LLM_API_KEY || '';
    this.llmApiUrl = process.env.LLM_API_URL || 'https://api.openai.com/v1/chat/completions';
    this.imageApiKey = process.env.IMAGE_API_KEY || '';
    this.imageApiUrl = process.env.IMAGE_API_URL || '';
  }

  /**
   * Generate story text using LLM
   */
  async generateStory(user: User): Promise<string> {
    // Reload environment variables to ensure we have the latest values
    this.reloadEnv();

    const prompt = this.buildPrompt(user);

    // Debug: Log API key status
    const hasKey = this.llmApiKey && this.llmApiKey.length > 10;
    console.log(`ğŸ”‘ API Key configured: ${hasKey} (length: ${this.llmApiKey?.length || 0})`);

    try {
      const response = await fetch(this.llmApiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.llmApiKey}`
        },
        body: JSON.stringify({
          model: 'gpt-3.5-turbo', // More widely available
          messages: [
            {
              role: 'system',
              content: 'ä½ æ˜¯ä¸€ä¸ªçˆ½æ–‡ä½œå®¶ï¼Œæ“…é•¿åˆ›ä½œä»£å…¥æ„Ÿå¼ºçš„çŸ­ç¯‡çˆ½æ–‡ç‰‡æ®µã€‚'
            },
            {
              role: 'user',
              content: prompt
            }
          ],
          max_tokens: 300,
          temperature: 0.8
        })
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error(`LLM API error: ${response.status} ${response.statusText}`);
        console.error(`Response body: ${errorText}`);
        throw new Error(`LLM API error: ${response.status} ${response.statusText}`);
      }

      const data = await response.json() as any;
      const text = data.choices[0].message.content.trim();

      // Validate length
      if (text.length < 80 || text.length > 500) {
        console.warn(`Generated text length ${text.length} is outside target range`);
      }

      console.log(`âœ… Story generated successfully: ${text.substring(0, 50)}...`);
      return text;
    } catch (error) {
      console.error('Failed to generate story:', error);
      // Return a fallback story
      return this.generateFallbackStory(user);
    }
  }

  /**
   * Build the prompt based on user preferences
   */
  private buildPrompt(user: User): string {
    const genderMap: Record<string, string> = {
      male: 'ç”·æ€§',
      female: 'å¥³æ€§'
    };

    const genreMap: Record<string, string> = {
      modern: 'ç°ä»£éƒ½å¸‚',
      ancient: 'å¤ä»£è¨€æƒ…',
      fantasy: 'ç„å¹»ä¿®ä»™',
      urban: 'éƒ½å¸‚å¼‚èƒ½',
      business: 'å•†ä¸šå•†æˆ˜'
    };

    const emotionMap: Record<string, string> = {
      favored: 'è¢«åçˆ±/å® æºº',
      revenge: 'å†·é™åæ€/æ‰“è„¸',
      satisfaction: 'æš—çˆ½/é€†è¢­',
      growth: 'æˆé•¿/å¥‹æ–—'
    };

    const genderKey = user.gender || 'male';
    const genreKey = user.genre_preference || 'modern';
    const emotionKey = user.emotion_preference || 'satisfaction';

    const gender = genderMap[genderKey] || genderMap['male'];
    const genre = genreMap[genreKey] || genreMap['modern'];
    const emotion = emotionMap[emotionKey] || emotionMap['satisfaction'];

    return `è¯·åˆ›ä½œä¸€æ®µ80-150å­—çš„çˆ½æ–‡ç‰‡æ®µï¼Œè¦æ±‚ï¼š

1. ç¬¬äºŒäººç§°"ä½ "ï¼Œè®©è¯»è€…æˆä¸ºä¸»è§’
2. ä¸»è§’æ€§åˆ«ï¼š${gender}
3. é¢˜æé£æ ¼ï¼š${genre}
4. æƒ…ç»ªåŸºè°ƒï¼š${emotion}
5. å¼€å¤´å³é«˜æ½®ï¼Œæ— éœ€é“ºå«
6. å¼ºä»£å…¥æ„Ÿï¼Œè®©è¯»è€…èº«ä¸´å…¶å¢ƒ
7. ç”¨è¯ç²¾ç‚¼ï¼ŒèŠ‚å¥æ˜å¿«

è¯·ç›´æ¥è¾“å‡ºæ•…äº‹å†…å®¹ï¼Œä¸è¦åŠ æ ‡é¢˜æˆ–å¼•è¨€ã€‚`;
  }

  /**
   * Generate fallback story when API fails
   */
  private generateFallbackStory(user: User): string {
    const templates = [
      "æ¸…æ™¨çš„ç¬¬ä¸€ç¼•é˜³å…‰é€è¿‡è½åœ°çª—ï¼Œä½ ç¼“ç¼“çå¼€åŒçœ¼ï¼Œå‘ç°è‡ªå·±ç«Ÿèººåœ¨å¥¢åçš„æ€»è£åŠå…¬å®¤çœŸçš®æ²™å‘ä¸Šã€‚é‚£ä¸ªæ›¾ç»çœ‹ä¸èµ·ä½ çš„å‰è¾ˆï¼Œæ­¤åˆ»æ­£æ­æ•¬åœ°ç«™åœ¨é—¨å£ç­‰å¾…ä½ çš„æŒ‡ç¤ºã€‚ä½ å˜´è§’å¾®å¾®ä¸Šæ‰¬ï¼Œè¿™ä¸€åˆ‡æ‰åˆšåˆšå¼€å§‹ã€‚",
      "ä¼šè®®å®¤çš„é—¨è¢«æ¨å¼€ï¼Œæ‰€æœ‰äººå±æ¯ä»¥å¾…ã€‚ä½ ä»å®¹åœ°èµ°è¿›å»ï¼Œå°†é‚£ä»½ä»·å€¼åäº¿çš„åˆåŒæ”¾åœ¨æ¡Œä¸Šã€‚æ›¾ç»è´¨ç–‘ä½ çš„å£°éŸ³æ­¤åˆ»å…¨éƒ¨æ¶ˆå¤±ï¼Œå–è€Œä»£ä¹‹çš„æ˜¯æ•¬ä½©çš„çœ¼ç¥ã€‚ä½ çŸ¥é“ï¼Œç”¨å®åŠ›è¯´è¯æ°¸è¿œæ˜¯æœ€å¥½çš„æ–¹å¼ã€‚",
      "å¤œå¹•é™ä¸´ï¼ŒåŸå¸‚çš„éœ“è™¹ç¯åœ¨ä½ è„šä¸‹é—ªçƒã€‚ä½ ç«™åœ¨é¡¶å±‚å…¬å¯“çš„è½åœ°çª—å‰ï¼Œå›æƒ³ä¸€è·¯èµ°æ¥çš„è‰°è¾›ã€‚é‚£äº›æ›¾ç»çš„å˜²ç¬‘å’Œè´¨ç–‘ï¼Œå¦‚ä»Šéƒ½æˆäº†ä½ æˆåŠŸçš„æ³¨è„šã€‚ä½ è½»è½»ä¸¾èµ·é…’æ¯ï¼Œæ•¬è‡ªå·±ï¼Œä¹Ÿæ•¬è¿™ä¸ªå±äºä½ çš„æ—¶ä»£ã€‚",
      "å½“é‚£ä¸ªç†Ÿæ‚‰çš„åå­—å‡ºç°åœ¨è·å¥–åå•ä¸Šæ—¶ï¼Œå…¨åœºçˆ†å‘å‡ºé›·é¸£èˆ¬çš„æŒå£°ã€‚ä½ ä¼˜é›…åœ°èµ°ä¸Šèˆå°ï¼Œæ¥è¿‡å¥–æ¯çš„é‚£ä¸€åˆ»ï¼Œé—ªå…‰ç¯æ­¤èµ·å½¼ä¼ã€‚ä½ çŸ¥é“ï¼Œè¿™ä¸ä»…æ˜¯å¯¹ä½ æ‰åçš„è®¤å¯ï¼Œæ›´æ˜¯å¯¹æ‰€æœ‰åšæŒæ¢¦æƒ³çš„äººçš„é¼“èˆã€‚",
      "ä½ æ¨å¼€é—¨çš„ç¬é—´ï¼Œæ•´ä¸ªæˆ¿é—´å®‰é™äº†ä¸‹æ¥ã€‚é‚£äº›æ›¾ç»çœ‹ä¸èµ·ä½ çš„äººï¼Œæ­¤åˆ»éƒ½ç”¨ä»°æ…•çš„çœ¼ç¥çœ‹ç€ä½ ã€‚ä½ å¾®å¾®ä¸€ç¬‘ï¼Œä»€ä¹ˆéƒ½æ²¡è¯´ï¼Œä½†ä½ çš„å‡ºç°æœ¬èº«å°±æ˜¯æœ€å¥½çš„è¯æ˜ã€‚æˆåŠŸçš„è·¯ä¸Šæ²¡æœ‰æ·å¾„ï¼Œä½†ä½ åšåˆ°äº†ã€‚"
    ];

    return templates[Math.floor(Math.random() * templates.length)];
  }

  /**
   * Generate image URL using OpenAI DALL-E
   */
  async generateImage(storyText: string, user: User, userPhotoUrl?: string): Promise<string> {
    // Reload environment variables
    this.reloadEnv();

    // Extract key elements from story for image prompt
    const imagePrompt = this.buildImagePrompt(storyText, user);

    console.log(`ğŸ¨ Generating image with DALL-E...`);
    console.log(`ğŸ“ Image prompt: ${imagePrompt.substring(0, 100)}...`);
    console.log(`ğŸ“¸ User photo available: ${userPhotoUrl ? 'YES' : 'NO'}`);

    // Check if image API key is configured
    const hasImageKey = this.imageApiKey && this.imageApiKey.length > 10;
    if (!hasImageKey) {
      console.warn(`âš ï¸  Image API key not configured, using placeholder`);
      return this.getPlaceholderImage(user);
    }

    // Use OpenAI DALL-E to generate image
    try {
      const requestBody = {
        model: 'dall-e-3',
        prompt: imagePrompt,
        n: 1,
        size: '1024x1024' as const,
        quality: 'standard' as const,
        style: 'vivid' as const
      };

      console.log(`ğŸ”„ Calling DALL-E API...`);

      const response = await fetch(this.imageApiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.imageApiKey}`
        },
        body: JSON.stringify(requestBody)
      });

      if (!response.ok) {
        const errorText = await response.text();
        console.error(`âŒ DALL-E API error: ${response.status} ${response.statusText}`);
        console.error(`Response: ${errorText}`);
        throw new Error(`DALL-E API error: ${response.status}`);
      }

      const data = await response.json() as any;
      const imageUrl = data.data[0].url;

      console.log(`âœ… Image generated successfully: ${imageUrl.substring(0, 60)}...`);
      return imageUrl;
    } catch (error) {
      console.error('âŒ Failed to generate image with DALL-E:', error);
      console.log(`ğŸ“¦ Using placeholder image instead`);
      return this.getPlaceholderImage(user);
    }
  }

  /**
   * Get placeholder image URL as fallback
   */
  private getPlaceholderImage(user: User): string {
    const gender = user.gender === 'male' ? 'male' : 'female';
    const genre = user.genre_preference || 'modern';
    return `https://placehold.co/600x800/1a1a2e/eeaeee?text=${encodeURIComponent(`Daily+Story+${gender}+${genre}`)}`;
  }

  /*
  // Future: If user photo is available, we could use image-to-image generation
  // This would require a different API or service that supports img2img
  if (userPhotoUrl) {
    console.log(`ğŸ’¡ User photo provided, but DALL-E doesn't support image-to-image yet`);
    console.log(`ğŸ’¡ In the future, we could use a service like Stability AI for this`);
    // For now, we'll still generate a new image with DALL-E
  }
  */

  /**
   * Build image prompt from story text and user preferences
   */
  private buildImagePrompt(storyText: string, user: User): string {
    const gender = user.gender === 'male' ? 'handsome man' : 'beautiful woman';
    const genreKey = user.genre_preference || 'modern';

    const styleMap: Record<string, string> = {
      modern: 'modern professional',
      ancient: 'ancient chinese historical',
      fantasy: 'fantasy magical',
      urban: 'urban city',
      business: 'business executive'
    };

    const style = styleMap[genreKey] || 'modern professional';

    // Build a detailed prompt based on the story
    return `A ${style} portrait of a ${gender}, in a success moment, cinematic lighting, high quality, detailed, 8k resolution, professional photography, vibrant colors`;
  }
}

export const contentGenerator = new ContentGenerator();
